<h1>ToqiNet<h1>
<h2>Model Overview</h2>

<p>ToqiNet is an advanced deep learning model tailored for image classification tasks. It utilizes convolutional neural networks (CNNs) to extract features from input images and make accurate predictions about their respective classes. In this section, we'll explore how ToqiNet works and delve into its underlying algorithms and functionality.</p>

<h3>Functionality</h3>

<p>ToqiNet operates by processing input images through a series of convolutional and pooling layers to extract meaningful features. These features are then fed into fully connected layers for classification. Let's break down the key components of ToqiNet's functionality:</p>

<h4>Convolutional Layers</h4>

<p>The convolutional layers in ToqiNet serve as feature extractors, detecting patterns and shapes within the input images. Each convolutional layer applies a set of learnable filters to the input, producing feature maps that highlight relevant spatial information.</p>

<h4>Pooling Layers</h4>

<p>Pooling layers in ToqiNet reduce the spatial dimensions of the feature maps generated by the convolutional layers. This helps in capturing the most salient features while discarding redundant information, leading to more efficient processing and improved generalization.</p>

<h4>Fully Connected Layers</h4>

<p>The fully connected layers in ToqiNet take the flattened feature vectors from the preceding layers and perform classification based on learned representations. These layers enable ToqiNet to make predictions about the input images' classes with high accuracy.</p>

<h3>Algorithm</h3>

<p>Behind the scenes, ToqiNet employs sophisticated algorithms to optimize model performance and enhance training efficiency. Let's explore some of the key algorithms used in ToqiNet:</p>

<h4>Stochastic Gradient Descent (SGD)</h4>

<p>ToqiNet utilizes SGD as the optimization algorithm to iteratively update the model parameters based on the gradients computed from mini-batches of training data. SGD helps ToqiNet converge towards optimal parameter values and improves its ability to generalize to unseen data.</p>

<h4>Cross-Entropy Loss</h4>

<p>ToqiNet employs cross-entropy loss as the objective function to measure the discrepancy between the predicted class probabilities and the ground truth labels. By minimizing the cross-entropy loss during training, ToqiNet learns to make more accurate predictions and achieve higher classification accuracy.</p>

<h2>Training and Evaluation</h2>

<p>To train ToqiNet, we utilize labeled image datasets and follow a standard training procedure:</p>

<ol>
  <li>Prepare the training and validation datasets, ensuring proper data preprocessing and augmentation.</li>
  <li>Instantiate the ToqiNet model and define the optimizer and loss function.</li>
  <li>Iterate over the training dataset in mini-batches, computing predictions, calculating loss, and updating model parameters using backpropagation.</li>
  <li>Evaluate the trained model's performance on the validation dataset to assess its accuracy and generalization capability.</li>
</ol>

<h2>Usage</h2>
<h2>Code Snippets</h2>

<h3>Model Initialization and Setup</h3>

<p>Initialize the ToqiNet model, set up the device (GPU if available), and define other necessary configurations.</p>

<pre><code>import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
from collections import defaultdict
from ToqiNet import ToqiNet
from CustomDataset import CustomDataset

# Set device (GPU if available, otherwise CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define input shape and number of classes
input_shape = (3, 256, 256)  
num_classes = 2 

# Initialize ToqiNet model
model = ToqiNet(num_classes=2)
model.to(device)

# Load datasets
train_dataset = CustomDataset(root_dir='dataset/training_set', transform=model.transform)
test_dataset = CustomDataset(root_dir='dataset/test_set', transform=model.transform)

# Define data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32)
</code></pre>

<h3>Training the Model</h3>

<p>Train the ToqiNet model using the defined data loaders, optimizer, and loss function.</p>

<pre><code># Define optimizer and loss function
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Define training parameters
num_epochs = 100
print_every = 5

# Training loop
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    pbar = tqdm(enumerate(train_loader), total=len(train_loader))
    for i, (inputs, labels) in pbar:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        pbar.set_description(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / (i + 1):.4f}")

    if (epoch + 1) % print_every == 0:
        print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}")
</code></pre>

<h3>Saving the Model</h3>

<p>Save the trained model and class labels to files for future use.</p>

<pre><code># Save the trained model
torch.save({
    'model_state_dict': model.state_dict(),
    'class_labels': train_dataset.data.class_to_idx
}, 'ToqiNet.pt')

# Save class labels to a file
with open('class_labels.txt', 'w') as f:
    for class_name, class_idx in train_dataset.data.class_to_idx.items():
        f.write(f'{class_name}: {class_idx}\n')
</code></pre>

<h3>Evaluating Model Performance</h3>

<p>Evaluate the performance of the trained model on the test dataset.</p>

<pre><code># Evaluate model performance
model.eval()
correct = 0
total = 0

class_correct = defaultdict(int)
class_total = defaultdict(int)

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        for pred, label in zip(predicted.cpu().numpy(), labels.cpu().numpy()):
            class_correct[pred] += int(pred == label)
            class_total[label] += 1

accuracy = 100 * correct / total
print('Accuracy of the network on the test images: %.2f %%' % accuracy)

for class_name, class_idx in test_dataset.data.class_to_idx.items():
    print(f'Class: {class_name}, Total Images: {class_total[class_idx]}')
</code></pre>
<h3>Model Training</h3>

<p>Training ToqiNet is a meticulously orchestrated process that leverages advanced optimization techniques and rigorous validation protocols. Powered by sophisticated algorithms and cutting-edge hardware, ToqiNet undergoes extensive training to ensure superior performance and robustness. Rigorous testing and validation procedures validate ToqiNet's proficiency and reliability across diverse datasets and scenarios.</p>

<h2>Test Results</h2>

<h3>Tested Hardware Configuration</h3>

<ul>
  <li>Processor: Intel Core i7 11th Gen.</li>
  <li>Graphics Card: NVIDIA Tesla P100</li>
  <li>Memory: 16GB RAM</li>
</ul>

<h3>Test Results Summary</h3>

<table>
  <thead>
    <tr>
      <th>Model Name</th>
      <th>Test Images (both classes)</th>
      <th>Accuracy</th>
      <th>Parameters</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ToqiNet</td>
      <td>8000</td>
      <td>91.60%</td>
      <td>71M</td>
    </tr>
  </tbody>
</table>

<h2>Data Loss and Validation Graphs</h2>

<h3>Data Loss Graph</h3>

<p>The data loss graph illustrates the convergence of the training process over successive epochs. A decreasing trend in data loss indicates that ToqiNet is effectively learning from the training data and improving its predictive capabilities.</p>

<h3>Validation Accuracy Graph</h3>

<p>The validation accuracy graph provides insights into ToqiNet's generalization performance on unseen data. By monitoring the validation accuracy throughout the training process, we can evaluate ToqiNet's ability to generalize to new images and detect potential overfitting or underfitting issues.</p>

<h2>Usage</h2>

<p>For usage instructions and installation details, please refer to the <a href="docs/README.md">documentation</a>.</p>

<h2>Contributions</h2>

<p>Contributions to ToqiNet are welcome and encouraged. As an open-source project, ToqiNet thrives on collaboration and community involvement. If you encounter any issues or have suggestions for enhancements, please don't hesitate to open an issue or submit a pull request.</p>

<h2>License and Copyright</h2>

<p>Â© 2024 ToqiNet Contributors</p>

<p>This project is licensed under the MIT License. It is usable for any development and encourages open-source contributions.</p>

<p>For inquiries, please contact tahmeedtoqi123@gmail.com.</p>

<p><a href="https://web.facebook.com/tahmeedtoqi777/">account</a>.</p>
